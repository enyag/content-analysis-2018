{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lucem_illud #pip install -U git+git://github.com/Computational-Content-Analysis-2018/lucem_illud.git\n",
    "\n",
    "#All these packages need to be installed from pip\n",
    "#For NLP\n",
    "import nltk\n",
    "import scipy #For divergences/distances\n",
    "import seaborn as sns #makes our plots look nicer\n",
    "import sklearn.manifold #For a manifold plot\n",
    "from nltk.corpus import stopwords #For stopwords\n",
    "\n",
    "import numpy as np #For arrays\n",
    "import pandas #Gives us DataFrames\n",
    "import matplotlib.pyplot as plt #For graphics\n",
    "\n",
    "#Displays the graphs\n",
    "import graphviz #You also need to install the command line graphviz\n",
    "\n",
    "#These are from the standard library\n",
    "import os.path\n",
    "import zipfile\n",
    "import subprocess\n",
    "import io\n",
    "import tempfile\n",
    "\n",
    "#additionally...\n",
    "import chardet\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting downloads, this will take 5-10 minutes\n",
      "../stanford-NLP/parser already exists, skipping download\n",
      "../stanford-NLP/ner already exists, skipping download\n",
      "../stanford-NLP/postagger already exists, skipping download\n",
      "../stanford-NLP/core already exists, skipping download\n",
      "Done setting up the Stanford NLP collection\n"
     ]
    }
   ],
   "source": [
    "lucem_illud.setupStanfordNLP()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/nltk/tag/stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "/anaconda3/lib/python3.6/site-packages/nltk/tag/stanford.py:149: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordPOSTagger, self).__init__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import lucem_illud.stanford as stanford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date                                              title  \\\n",
      "0    12/1/16  Preventing the Exploitation of Information and...   \n",
      "1   10/10/16  Keynote Address at the Singapore International...   \n",
      "2    9/28/16  The Persistent Threat of North Korea and Devel...   \n",
      "3    9/19/16  Statement Before the Presidential Commission o...   \n",
      "4     6/3/16                                   TEDx Tysons Talk   \n",
      "5    5/25/16  International Cybersecurity Strategy: Deterrin...   \n",
      "6     3/1/16  Remarks by Attorney General Loretta E. Lynch a...   \n",
      "7    2/26/16  Inter-American Committee Against Terrorism (CI...   \n",
      "8    2/11/16  The New Face of Terrorism: Countering Violent ...   \n",
      "9    7/29/15  Remarks for Panel Session \"Development of Cybe...   \n",
      "10    5/4/15  Department of Commerce Cybersecurity Trade Mis...   \n",
      "11   2/24/15                      New Reward for Cyber Fugitive   \n",
      "12   1/13/15  The North Korean Threat: Nuclear, Missiles and...   \n",
      "13    3/4/14  As Prepared Remarks at Georgetown University I...   \n",
      "14   12/3/13  Remarks at a Cyber Partnership Agreement Signi...   \n",
      "15  10/21/13             Remarks at High Level Leader's Meeting   \n",
      "16  11/26/12  Cyber Security: Project Cyber Monday 3 and Pro...   \n",
      "17   10/5/12    Video Remarks for the Budapest Cyber Conference   \n",
      "18   9/18/12                    International Law in Cyberspace   \n",
      "19   8/31/12  The Organization of American States' Inter-Ame...   \n",
      "20    3/7/12       Strengthening Cyber Security in the Americas   \n",
      "21  11/17/11  Leading With Diplomacy to Strengthen Stability...   \n",
      "22  10/31/11  Background Briefing: Secretary Clinton's Parti...   \n",
      "23  10/18/11                               Cybersecurity Update   \n",
      "24   5/18/11  Release of the Obama Administration's Internat...   \n",
      "25   5/16/11  Remarks on the Release of President Obama Admi...   \n",
      "\n",
      "                                                 text  \n",
      "0   I would like to begin by thanking the UN Count...  \n",
      "1   Good morning! Thank you to Prime Minister Lee ...  \n",
      "2   Introduction. Chairman Gardner, Ranking Member...  \n",
      "3   Chairman Donilon, Vice Chairman Palmisano, and...  \n",
      "4   So what do zombies have to do with diplomacy? ...  \n",
      "5   Chairman Gardner, Ranking Member Cardin, membe...  \n",
      "6   Good afternoon, and thank you for that warm we...  \n",
      "7   Background: The Sixteenth Regular Session of t...  \n",
      "8   Good afternoon. IÍm looking forward to our dis...  \n",
      "9   Thank you for the opportunity to discuss devel...  \n",
      "10  Great. Well, thank you, and first of all good ...  \n",
      "11  ASSISTANT ATTORNEY GENERAL CALDWELL: Thank you...  \n",
      "12  Mr. Chairman, Ranking Member Engel, and Member...  \n",
      "13  ItÍs a pleasure to be here today. I want to be...  \n",
      "14  MODERATOR: Good afternoon, and thank you all f...  \n",
      "15  Good morning, Minister, Chairman Sasongko, Mr....  \n",
      "16  MODERATOR: Good afternoon, everyone. The Forei...  \n",
      "17  I am delighted to be able to send greetings to...  \n",
      "18  Thank you, Colonel Brown, for your kind invita...  \n",
      "19  Good Morning. Mr. Assistant Secretary General ...  \n",
      "20  I want to thank the Committee for the opportun...  \n",
      "21  Thank you for your kind introduction. I am hon...  \n",
      "22  MS. FULTON: All right. Thank you. And thanks e...  \n",
      "23  MR. PAINTER: Thanks, and thanks for coming her...  \n",
      "24  MODERATOR: Thank you, everyone, for coming to ...  \n",
      "25  Well, thank you very much. As you can guess fr...  \n"
     ]
    }
   ],
   "source": [
    "DOSSpeeches = '/Users/Enya/Desktop/DOS_Speeches.csv'\n",
    "DOSSpeechesDF = pandas.read_csv(DOSSpeeches, encoding='Latin-1')\n",
    "print (DOSSpeechesDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOSSpeechesDF['tokenized-text'] = DOSSpeechesDF['text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "DOSSpeechesDF['sentences'] = DOSSpeechesDF['text'].apply(lambda x: [nltk.word_tokenize(s) for s in nltk.sent_tokenize(x)])\n",
    "DOSSpeechesDF['POS-sents'] = DOSSpeechesDF['sentences'].apply(lambda x: stanford.postTagger.tag_sents(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cyber', 265),\n",
       " ('cyberspace', 202),\n",
       " ('law', 145),\n",
       " ('security', 123),\n",
       " ('world', 84),\n",
       " ('policy', 83),\n",
       " ('information', 82),\n",
       " ('internet', 73),\n",
       " ('', 71),\n",
       " ('behavior', 69),\n",
       " ('space', 66),\n",
       " ('today', 64),\n",
       " ('cooperation', 63),\n",
       " ('state', 63),\n",
       " ('stability', 63),\n",
       " ('capacity', 56),\n",
       " ('technology', 52),\n",
       " ('Internet', 51),\n",
       " ('work', 49),\n",
       " ('consensus', 48),\n",
       " ('development', 48),\n",
       " ('time', 46),\n",
       " ('role', 45),\n",
       " ('building', 45),\n",
       " ('cybersecurity', 45)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countTarget = 'NN'\n",
    "targetCounts = {}\n",
    "for entry in DOSSpeechesDF['POS-sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != countTarget:\n",
    "                continue\n",
    "            elif ent in targetCounts:\n",
    "                targetCounts[ent] += 1\n",
    "            else:\n",
    "                targetCounts[ent] = 1\n",
    "sortedTargets = sorted(targetCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedTargets[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('be', 166),\n",
       " ('do', 52),\n",
       " ('build', 49),\n",
       " ('promote', 46),\n",
       " ('continue', 45),\n",
       " ('have', 39),\n",
       " ('work', 34),\n",
       " ('take', 34),\n",
       " ('make', 34),\n",
       " ('ensure', 33),\n",
       " ('Thank', 30),\n",
       " ('address', 29),\n",
       " ('engage', 26),\n",
       " ('help', 22),\n",
       " ('strengthen', 20),\n",
       " ('thank', 19),\n",
       " ('protect', 18),\n",
       " ('bring', 18),\n",
       " ('achieve', 18),\n",
       " ('apply', 18),\n",
       " ('play', 17),\n",
       " ('develop', 17),\n",
       " ('reduce', 17),\n",
       " ('see', 16),\n",
       " ('counter', 15)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countTarget = 'VB'\n",
    "targetCounts = {}\n",
    "for entry in DOSSpeechesDF['POS-sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != countTarget:\n",
    "                continue\n",
    "            elif ent in targetCounts:\n",
    "                targetCounts[ent] += 1\n",
    "            else:\n",
    "                targetCounts[ent] = 1\n",
    "sortedTargets = sorted(targetCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedTargets[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mainstream', 'secure', 'peaceful', 'domestic', 'stable', 'military', 'key', 'reliable', 'international', 'accessible'}\n"
     ]
    }
   ],
   "source": [
    "NTarget = 'JJ'\n",
    "Word = 'cyberspace'\n",
    "NResults = set()\n",
    "for entry in DOSSpeechesDF['POS-sents']:\n",
    "    for sentence in entry:\n",
    "        for (ent1, kind1),(ent2,kind2) in zip(sentence[:-1], sentence[1:]):\n",
    "            if (kind1,ent2.lower())==(NTarget,Word):\n",
    "                NResults.add(ent1)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "print(NResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'global', 'large-scale', 'states/International', 'hostile', 'complicated', 'significant', 'new', 'fundamental', 'cross-cutting', 'first', 'joint', 'bilateral', 'reliable', 'malicious', 'regional', 'big', 'transnational', 'potential', 'future', 'voluntary', 'whole-of-government', 'serious', 'sub-regional', 'sophisticated', 'foreign', 'recent', 'major', 'offensive', 'particular', 'specific', 'coercive', 'specialized', 'practical', 'other', 'international'}\n"
     ]
    }
   ],
   "source": [
    "NTarget = 'JJ'\n",
    "Word = 'cyber'\n",
    "NResults = set()\n",
    "for entry in DOSSpeechesDF['POS-sents']:\n",
    "    for sentence in entry:\n",
    "        for (ent1, kind1),(ent2,kind2) in zip(sentence[:-1], sentence[1:]):\n",
    "            if (kind1,ent2.lower())==(NTarget,Word):\n",
    "                NResults.add(ent1)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "print(NResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'document', 'aviation', 'chain', 'cyber', 'space', 'network', 'computer'}\n"
     ]
    }
   ],
   "source": [
    "NTarget = 'NN'\n",
    "Word = 'security'\n",
    "NResults = set()\n",
    "for entry in DOSSpeechesDF['POS-sents']:\n",
    "    for sentence in entry:\n",
    "        for (ent1, kind1),(ent2,kind2) in zip(sentence[:-1], sentence[1:]):\n",
    "            if (kind1,ent2.lower())==(NTarget,Word):\n",
    "                NResults.add(ent1)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "print(NResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'economic', 'shared', 'knowledgeable', 'national', 'multinational', 'hemispheric', 'private-sector', 'new', 'trilateral', 'regional', 'cyber', 'international'}\n"
     ]
    }
   ],
   "source": [
    "NTarget = 'JJ'\n",
    "Word = 'security'\n",
    "NResults = set()\n",
    "for entry in DOSSpeechesDF['POS-sents']:\n",
    "    for sentence in entry:\n",
    "        for (ent1, kind1),(ent2,kind2) in zip(sentence[:-1], sentence[1:]):\n",
    "            if (kind1,ent2.lower())==(NTarget,Word):\n",
    "                NResults.add(ent1)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "print(NResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
